"""
AdGenesis ML Service - Design Blueprint Generation
Serves the fine-tuned model that generates structured JSON design blueprints
"""

import json
import os
import torch
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig
from peft import PeftModel
from pathlib import Path
from typing import Optional, List, Dict, Any
import random

# Load environment variables from .env file
try:
    from dotenv import load_dotenv
    load_dotenv(Path(__file__).parent.parent / ".env")
    print("âœ“ Environment variables loaded from .env")
except ImportError:
    print("âš  python-dotenv not installed. Install with: pip install python-dotenv")
except Exception as e:
    print(f"âš  Could not load .env file: {e}")

# Import design schema and templates
from design_schema import (
    DesignBlueprint, 
    blueprint_to_fabric_json,
    FORMAT_SPECS,
    PLATFORM_GUIDELINES,
    EXAMPLE_BLUEPRINT,
)

# Import modern design system
from modern_design_system import (
    MODERN_COLOR_SCHEMES,
    MODERN_LAYOUTS,
    MODERN_FONTS,
    MODERN_HEADLINES,
    MODERN_SUBHEADLINES,
    MODERN_CTAS,
    detect_category,
    generate_modern_decorations
)
from modern_blueprint_generator import generate_modern_design_blueprint

# Import retail design system
from retail_design_system import (
    RetailDesignGenerator,
    Platform,
    DesignTone,
    RETAIL_COLOR_PALETTES,
    PLATFORM_SPECS,
    ComplianceEngine,
    create_protein_bar_creative
)

# Import professional design generator (HIGH QUALITY)
from professional_design_generator import (
    generate_professional_design,
    professional_blueprint_to_fabric,
    PROFESSIONAL_PALETTES,
    PROFESSIONAL_LAYOUTS,
    INDUSTRY_CONTENT,
    detect_industry,
)

# Import PREMIUM graphic design generator (AGENCY QUALITY)
from premium_design_generator import (
    generate_premium_design,
    premium_blueprint_to_fabric,
    ALL_PALETTES,
)

# Import SMART design generator (PROMPT-BASED GENERATION)
from smart_design_generator import (
    generate_smart_design,
    smart_blueprint_to_fabric,
    analyze_prompt,
)

# Import CREATIVE DIRECTOR (TRUE PROMPT-DRIVEN GENERATION)
from creative_director import (
    CreativeDirector,
    generate_creative_design,
    blueprint_to_fabric as creative_blueprint_to_fabric,
    PromptAnalyzer,
)

# Import GENERATIVE DESIGNER - Zero Templates, Pure Computation
from generative_designer import (
    generate_design as generative_generate_design,
    blueprint_to_fabric as generative_blueprint_to_fabric,
    extract_all_entities,
    compute_prompt_metrics,
)

# Import AI Image Generator - Uses Hugging Face API
from image_generator import ImageGenerator, image_generator

# =============================================================================
# APP SETUP
# =============================================================================

app = FastAPI(
    title="AdGenesis Design Service",
    version="3.0.0",
    description="AI-powered ad design blueprint generation"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global state
model = None
tokenizer = None
model_loaded = False

# =============================================================================
# REQUEST/RESPONSE MODELS
# =============================================================================

class DesignRequest(BaseModel):
    """Request to generate a design blueprint"""
    prompt: str = Field(..., description="User's ad description")
    platform: str = Field(default="meta", description="meta, google, linkedin, twitter, tiktok")
    format: str = Field(default="square", description="square, story, landscape, portrait, wide")
    industry: Optional[str] = Field(default=None, description="e-commerce, saas, fitness, etc.")
    tone: Optional[str] = Field(default="professional", description="professional, playful, urgent, etc.")
    brand_colors: Optional[List[str]] = Field(default=None, description="Brand color hex codes")
    brand_fonts: Optional[List[str]] = Field(default=None, description="Brand font names")

class DesignResponse(BaseModel):
    """Generated design blueprint"""
    success: bool
    blueprint: Dict[str, Any]
    fabric_json: Dict[str, Any]
    message: Optional[str] = None

class TemplateListResponse(BaseModel):
    """List of available templates"""
    templates: List[Dict[str, Any]]

class ComplianceCheckRequest(BaseModel):
    """Request to check design compliance"""
    blueprint: Dict[str, Any]
    platform: str

class ComplianceCheckResponse(BaseModel):
    """Compliance check result"""
    compliant: bool
    issues: List[str]
    suggestions: List[str]


class RetailCreativeRequest(BaseModel):
    """Request for retail-focused creative generation"""
    brand_name: str = Field(..., description="Brand name")
    brand_colors: Dict[str, str] = Field(
        default={"primary": "#1E1E2F", "accent": "#F5B700", "secondary": "#FFFFFF"},
        description="Brand color palette with primary, accent, secondary"
    )
    headline: str = Field(..., description="Main headline text")
    subheadline: Optional[str] = Field(default=None, description="Secondary headline")
    cta: str = Field(default="Shop Now", description="Call to action text")
    offer: Optional[str] = Field(default=None, description="Offer text e.g. '20% OFF'")
    trust_signals: Optional[List[Dict[str, str]]] = Field(
        default=None,
        description="Trust badges e.g. [{'icon': 'ðŸŒ±', 'text': 'Plant-Based'}]"
    )
    products: Optional[List[Dict[str, Any]]] = Field(
        default=None,
        description="Product information with images"
    )
    platform: str = Field(default="instagram_feed", description="Target platform")
    tone: str = Field(default="bold_fmcg", description="Design tone")
    logo_url: Optional[str] = Field(default=None, description="Logo image URL")


class RetailCreativeResponse(BaseModel):
    """Response with generated retail creative"""
    success: bool
    design: Dict[str, Any]
    variants: Optional[List[Dict[str, Any]]] = None
    all_formats: Optional[Dict[str, Dict[str, Any]]] = None
    compliance: Dict[str, Any]
    message: Optional[str] = None

# =============================================================================
# DESIGN GENERATION (Fallback/Rule-based)
# =============================================================================

# Color palettes organized by tone
COLOR_PALETTES = {
    "professional": [
        {"primary": "#2563EB", "secondary": "#1E40AF", "background": "#0F172A", "text_primary": "#F8FAFC", "text_secondary": "#94A3B8", "accent": "#3B82F6"},
        {"primary": "#0D9488", "secondary": "#115E59", "background": "#042F2E", "text_primary": "#F0FDFA", "text_secondary": "#5EEAD4", "accent": "#14B8A6"},
        {"primary": "#6366F1", "secondary": "#4F46E5", "background": "#0F0F23", "text_primary": "#E0E7FF", "text_secondary": "#A5B4FC", "accent": "#818CF8"},
    ],
    "playful": [
        {"primary": "#EC4899", "secondary": "#F472B6", "background": "#1F1235", "text_primary": "#FEFCE8", "text_secondary": "#FDE68A", "accent": "#FBBF24"},
        {"primary": "#8B5CF6", "secondary": "#A78BFA", "background": "#1E1B4B", "text_primary": "#FFFFFF", "text_secondary": "#C4B5FD", "accent": "#F472B6"},
    ],
    "urgent": [
        {"primary": "#DC2626", "secondary": "#EF4444", "background": "#18181B", "text_primary": "#FFFFFF", "text_secondary": "#FCA5A5", "accent": "#FBBF24"},
        {"primary": "#EA580C", "secondary": "#F97316", "background": "#1C1917", "text_primary": "#FFFBEB", "text_secondary": "#FDBA74", "accent": "#FACC15"},
    ],
    "luxurious": [
        {"primary": "#D4AF37", "secondary": "#B8860B", "background": "#0C0A09", "text_primary": "#FAFAF9", "text_secondary": "#A8A29E", "accent": "#F5D77A"},
        {"primary": "#9333EA", "secondary": "#7C3AED", "background": "#0F0520", "text_primary": "#FAF5FF", "text_secondary": "#C4B5FD", "accent": "#D4AF37"},
    ],
    "minimalist": [
        {"primary": "#18181B", "secondary": "#3F3F46", "background": "#FAFAFA", "text_primary": "#09090B", "text_secondary": "#71717A", "accent": "#18181B"},
        {"primary": "#FFFFFF", "secondary": "#E4E4E7", "background": "#09090B", "text_primary": "#FAFAFA", "text_secondary": "#A1A1AA", "accent": "#FAFAFA"},
    ],
    "bold": [
        {"primary": "#7C3AED", "secondary": "#8B5CF6", "background": "#030712", "text_primary": "#FFFFFF", "text_secondary": "#9CA3AF", "accent": "#06B6D4"},
        {"primary": "#059669", "secondary": "#10B981", "background": "#022C22", "text_primary": "#ECFDF5", "text_secondary": "#6EE7B7", "accent": "#FBBF24"},
    ],
    "friendly": [
        {"primary": "#F59E0B", "secondary": "#FBBF24", "background": "#1F2937", "text_primary": "#FFFFFF", "text_secondary": "#D1D5DB", "accent": "#34D399"},
        {"primary": "#06B6D4", "secondary": "#22D3EE", "background": "#0F172A", "text_primary": "#F0F9FF", "text_secondary": "#7DD3FC", "accent": "#F472B6"},
    ],
}

# Layout templates
LAYOUTS = {
    "centered": {
        "headline": {"x": 10, "y": 30, "w": 80, "h": 15},
        "subheadline": {"x": 15, "y": 50, "w": 70, "h": 10},
        "cta": {"x": 30, "y": 70, "w": 40, "h": 8},
    },
    "left_aligned": {
        "headline": {"x": 8, "y": 25, "w": 55, "h": 18},
        "subheadline": {"x": 8, "y": 48, "w": 50, "h": 10},
        "cta": {"x": 8, "y": 68, "w": 35, "h": 8},
    },
    "hero_top": {
        "headline": {"x": 5, "y": 15, "w": 90, "h": 20},
        "subheadline": {"x": 10, "y": 42, "w": 80, "h": 10},
        "cta": {"x": 25, "y": 72, "w": 50, "h": 10},
    },
    "bottom_focus": {
        "headline": {"x": 8, "y": 55, "w": 84, "h": 12},
        "subheadline": {"x": 12, "y": 70, "w": 76, "h": 8},
        "cta": {"x": 30, "y": 85, "w": 40, "h": 7},
    },
}

# Headlines and CTAs
HEADLINE_TEMPLATES = [
    "{action} Your {noun}",
    "Discover {noun}",
    "Transform Your {noun}",
    "The {adjective} Way to {action}",
    "{adjective} {noun} Awaits",
    "Unlock {noun} Today",
    "Experience {adjective} {noun}",
    "{action} Like Never Before",
]

CTA_OPTIONS = [
    "Shop Now", "Get Started", "Learn More", "Sign Up Free",
    "Try Free", "Download Now", "Explore", "Join Now",
    "Claim Offer", "Book Now", "Start Free Trial", "See More"
]

def extract_keywords(prompt: str) -> Dict[str, str]:
    """Extract keywords from prompt for headline generation"""
    words = prompt.lower().split()
    
    # Default values
    result = {
        "action": random.choice(["Discover", "Transform", "Unlock", "Experience"]),
        "noun": random.choice(["Success", "Growth", "Results", "Potential"]),
        "adjective": random.choice(["Amazing", "Revolutionary", "Powerful", "Smart"]),
    }
    
    # Industry-specific keywords
    industry_keywords = {
        "fitness": {"action": "Achieve", "noun": "Fitness Goals", "adjective": "Peak"},
        "ecommerce": {"action": "Shop", "noun": "Deals", "adjective": "Exclusive"},
        "saas": {"action": "Streamline", "noun": "Workflow", "adjective": "Smart"},
        "food": {"action": "Taste", "noun": "Flavors", "adjective": "Delicious"},
        "fashion": {"action": "Elevate", "noun": "Style", "adjective": "Trendy"},
        "tech": {"action": "Experience", "noun": "Innovation", "adjective": "Cutting-Edge"},
        "finance": {"action": "Grow", "noun": "Wealth", "adjective": "Secure"},
        "travel": {"action": "Explore", "noun": "Destinations", "adjective": "Dream"},
    }
    
    for industry, keywords in industry_keywords.items():
        if industry in prompt.lower():
            result.update(keywords)
            break
    
    return result

def generate_headline(prompt: str) -> str:
    """Generate a headline from prompt"""
    keywords = extract_keywords(prompt)
    template = random.choice(HEADLINE_TEMPLATES)
    
    headline = template.format(**keywords)
    return headline

def generate_subheadline(prompt: str) -> str:
    """Generate a subheadline"""
    templates = [
        "Your journey starts here",
        "Built for people like you",
        "Join thousands of satisfied customers",
        "Limited time offer",
        "No commitment required",
        "See the difference today",
    ]
    return random.choice(templates)

def generate_design_blueprint(request: DesignRequest) -> Dict[str, Any]:
    """
    Generate a complete MODERN design blueprint.
    Creates professional advertising-quality posters.
    """
    return generate_modern_design_blueprint(
        request, 
        MODERN_COLOR_SCHEMES, 
        MODERN_LAYOUTS,
        MODERN_HEADLINES, 
        MODERN_SUBHEADLINES, 
        MODERN_CTAS,
        MODERN_FONTS, 
        detect_category
    )

def blueprint_to_fabric(blueprint: Dict[str, Any]) -> Dict[str, Any]:
    """Convert blueprint to Fabric.js JSON format"""
    
    width = blueprint["metadata"]["width"]
    height = blueprint["metadata"]["height"]
    
    fabric_objects = []
    
    # Background
    bg_color = blueprint.get("background", {}).get("color", "#1a1a2e")
    fabric_objects.append({
        "type": "rect",
        "left": 0,
        "top": 0,
        "width": width,
        "height": height,
        "fill": bg_color,
        "selectable": False,
        "evented": False,
    })
    
    # Convert elements
    for element in blueprint.get("elements", []):
        pos = element.get("position", {"x": 0, "y": 0})
        size = element.get("size", {"width": 50, "height": 10})
        
        left = (pos["x"] / 100) * width
        top = (pos["y"] / 100) * height
        el_width = (size["width"] / 100) * width
        el_height = (size["height"] / 100) * height
        
        if element["type"] == "text":
            fabric_objects.append({
                "type": "textbox",
                "id": element.get("id", "text"),
                "left": left,
                "top": top,
                "width": el_width,
                "text": element.get("content", ""),
                "fontSize": element.get("font_size", 48),
                "fontFamily": element.get("font_family", "Inter"),
                "fontWeight": element.get("font_weight", 400),
                "fill": element.get("color", "#ffffff"),
                "textAlign": element.get("align", "center"),
                "lineHeight": element.get("line_height", 1.2),
                "charSpacing": element.get("letter_spacing", 0) * 10,
            })
        
        elif element["type"] == "shape":
            shape_obj = {
                "id": element.get("id", "shape"),
                "left": left,
                "top": top,
                "width": el_width,
                "height": el_height,
                "fill": element.get("fill_color", "#8B5CF6"),
                "opacity": element.get("opacity", 1),
            }
            
            if element.get("shape_type") == "circle":
                shape_obj["type"] = "circle"
                shape_obj["radius"] = min(el_width, el_height) / 2
            else:
                shape_obj["type"] = "rect"
                shape_obj["rx"] = element.get("corner_radius", 0)
                shape_obj["ry"] = element.get("corner_radius", 0)
            
            fabric_objects.append(shape_obj)
        
        elif element["type"] == "cta_button":
            # Button background
            fabric_objects.append({
                "type": "rect",
                "id": f"{element.get('id', 'cta')}_bg",
                "left": left,
                "top": top,
                "width": el_width,
                "height": el_height,
                "fill": element.get("background_color", "#8B5CF6"),
                "rx": element.get("corner_radius", 8),
                "ry": element.get("corner_radius", 8),
            })
            
            # Button text
            fabric_objects.append({
                "type": "textbox",
                "id": f"{element.get('id', 'cta')}_text",
                "left": left,
                "top": top + (el_height - element.get("font_size", 16)) / 2,
                "width": el_width,
                "text": element.get("text", "Click"),
                "fontSize": element.get("font_size", 16),
                "fontWeight": element.get("font_weight", 600),
                "fill": element.get("text_color", "#ffffff"),
                "textAlign": "center",
            })
    
    return {
        "version": "5.3.0",
        "objects": fabric_objects,
        "background": bg_color,
    }

# =============================================================================
# MODEL LOADING
# =============================================================================

def load_model(model_path: str):
    """Load the fine-tuned design model (supports both full models and LoRA adapters)"""
    global model, tokenizer, model_loaded
    
    model_path = Path(model_path)
    
    if not model_path.exists():
        print(f"âš ï¸ Model path {model_path} not found. Using rule-based generation.")
        return False
    
    try:
        print(f"ðŸ”„ Loading model from {model_path}")
        
        # Check if this is a LoRA adapter
        adapter_config_path = model_path / "adapter_config.json"
        is_lora_adapter = adapter_config_path.exists()
        
        if is_lora_adapter:
            print("ðŸ“Ž Detected LoRA adapter, loading with PEFT...")
            import json
            with open(adapter_config_path) as f:
                adapter_config = json.load(f)
            
            base_model_name = adapter_config.get("base_model_name_or_path", "gpt2-medium")
            print(f"   Base model: {base_model_name}")
            
            # Load tokenizer from adapter path
            tokenizer = AutoTokenizer.from_pretrained(model_path)
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
            
            # Load base model
            print(f"   Loading base model {base_model_name}...")
            base_model = AutoModelForCausalLM.from_pretrained(
                base_model_name,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
            )
            
            # Load LoRA adapter
            print(f"   Loading LoRA adapter...")
            model = PeftModel.from_pretrained(base_model, model_path)
            model = model.merge_and_unload()  # Merge for faster inference
            print("   âœ… LoRA adapter merged with base model")
        else:
            # Regular model loading
            tokenizer = AutoTokenizer.from_pretrained(model_path)
            if tokenizer.pad_token is None:
                tokenizer.pad_token = tokenizer.eos_token
            
            model = AutoModelForCausalLM.from_pretrained(
                model_path,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
                device_map="auto" if torch.cuda.is_available() else None,
            )
        
        model.eval()
        model_loaded = True
        print("âœ… Model loaded successfully")
        return True
        
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        model_loaded = False
        return False

def fix_json_string(json_str: str) -> str:
    """Fix common JSON issues from model output"""
    import re
    
    # Remove control characters
    json_str = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', json_str)
    
    # Fix trailing commas before } or ]
    json_str = re.sub(r',\s*}', '}', json_str)
    json_str = re.sub(r',\s*]', ']', json_str)
    
    # Fix missing quotes around keys (if word followed by colon without quotes)
    json_str = re.sub(r'(\{|,)\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', json_str)
    
    # Fix single quotes to double quotes
    json_str = json_str.replace("'", '"')
    
    # Fix escaped newlines in strings
    json_str = json_str.replace('\\n', ' ')
    
    return json_str

def extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
    """Extract valid JSON from model output using multiple strategies"""
    import re
    
    # Debug: print first 500 chars of output to understand structure
    print(f"ðŸ“„ Raw model output preview: {text[:500]}...")
    
    # Strategy 1: Find balanced braces
    json_start = text.find('{')
    if json_start == -1:
        print("âŒ No opening brace found in output")
        return None
    
    depth = 0
    best_json = None
    for i, char in enumerate(text[json_start:], json_start):
        if char == '{':
            depth += 1
        elif char == '}':
            depth -= 1
            if depth == 0:
                json_str = text[json_start:i+1]
                print(f"ðŸ“‹ Found potential JSON ({len(json_str)} chars)")
                try:
                    # Try direct parsing
                    result = json.loads(json_str)
                    print("âœ… Direct JSON parse succeeded!")
                    return result
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ Direct parse failed: {e}")
                    # Try with fixes
                    fixed = fix_json_string(json_str)
                    try:
                        result = json.loads(fixed)
                        print("âœ… Fixed JSON parse succeeded!")
                        return result
                    except json.JSONDecodeError as e2:
                        print(f"âš ï¸ Fixed parse also failed: {e2}")
                        # Store the best attempt
                        if best_json is None:
                            best_json = json_str
                # Continue looking for another valid JSON
    
    # Strategy 2: Try to build a minimal valid design from partial output
    if best_json:
        print(f"ðŸ”§ Attempting to salvage partial JSON...")
        # Try to extract key-value pairs manually
        try:
            # Extract headline if present
            headline_match = re.search(r'"headline"\s*:\s*"([^"]*)"', text)
            background_match = re.search(r'"background"\s*:\s*"([^"]*)"', text)
            
            if headline_match:
                salvaged = {
                    "headline": headline_match.group(1),
                    "background": background_match.group(1) if background_match else "#1a1a2e",
                    "elements": []
                }
                print(f"âœ… Salvaged basic design from partial output")
                return salvaged
        except Exception as e:
            print(f"âŒ Salvage failed: {e}")
    
    # Strategy 3: Try regex patterns for known structures
    patterns = [
        r'\{[^{}]*"elements"\s*:\s*\[[^\]]*\][^{}]*\}',
        r'\{[^{}]*"objects"\s*:\s*\[[^\]]*\][^{}]*\}',
        r'\{[^{}]*"headline"\s*:[^{}]*\}',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.DOTALL)
        for match in matches:
            try:
                result = json.loads(fix_json_string(match))
                print(f"âœ… Pattern match succeeded!")
                return result
            except:
                continue
    
    print("âŒ All extraction strategies failed")
    return None


def generate_with_model(request: DesignRequest) -> Optional[Dict[str, Any]]:
    """Generate design using the trained model"""
    if not model_loaded or model is None:
        print("âš ï¸ Model not loaded, skipping model generation")
        return None
    
    prompt_text = f"""You are an AI ad design assistant. Generate a complete design blueprint in JSON format.

Platform: {request.platform}
Format: {request.format}
Industry: {request.industry or 'general'}
Tone: {request.tone or 'professional'}

Prompt: {request.prompt}

Generate the design blueprint JSON:"""
    
    try:
        print(f"ðŸ§  Attempting model generation for: {request.prompt[:50]}...")
        inputs = tokenizer(prompt_text, return_tensors="pt", truncation=True, max_length=256)
        inputs = {k: v.to(model.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_new_tokens=500,  # Slightly increased for better JSON completion
                temperature=0.6,     # Lowered for more coherent output
                top_p=0.9,
                do_sample=True,
                pad_token_id=tokenizer.pad_token_id,
                use_cache=True,
            )
        
        text = tokenizer.decode(outputs[0], skip_special_tokens=True)
        print(f"ðŸ“ Model raw output length: {len(text)} chars")
        
        # Use improved JSON extraction
        result = extract_json_from_text(text)
        
        if result:
            print(f"âœ… Model generated valid design JSON!")
            return result
        
        print(f"âš ï¸ Could not extract valid JSON from model output")
        return None
    
    except Exception as e:
        print(f"âŒ Model generation failed: {e}")
        import traceback
        traceback.print_exc()
    
    return None

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.get("/")
async def root():
    return {
        "service": "AdGenesis Design Service",
        "version": "3.0.0",
        "model_loaded": model_loaded,
        "endpoints": [
            "/generate - Generate design blueprint",
            "/templates - Get template gallery",
            "/compliance - Check design compliance",
            "/health - Health check"
        ]
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "model_loaded": model_loaded,
        "gpu_available": torch.cuda.is_available()
    }


@app.get("/model-info")
async def model_info():
    """Get information about the loaded model"""
    if model_loaded and model is not None:
        return {
            "model_loaded": True,
            "model_type": "fine_tuned_lora" if hasattr(model, 'peft_config') else "full_model",
            "base_model": "gpt2-medium",
            "device": str(model.device) if hasattr(model, 'device') else "cpu",
            "inference_ready": True,
            "message": "Trained model is loaded and ready for inference"
        }
    else:
        return {
            "model_loaded": False,
            "model_type": None,
            "inference_ready": False,
            "message": "No model loaded. Using rule-based generation as fallback."
        }

@app.post("/generate", response_model=DesignResponse)
async def generate_design(request: DesignRequest):
    """
    Generate a UNIQUE design by DERIVING everything from the prompt.
    Uses GENERATIVE DESIGNER - Zero templates, pure computation.
    Every element is mathematically derived from the words in the prompt.
    INCLUDES AI-generated images via Hugging Face API.
    """
    try:
        print(f"\n{'='*70}")
        print(f"ðŸŽ¨ GENERATIVE DESIGNER - Zero Templates, Pure Computation")
        print(f"   Prompt: {request.prompt}")
        print(f"{'='*70}")
        
        # Step 1: Extract entities from prompt
        entities = extract_all_entities(request.prompt)
        print(f"\nðŸ“Š EXTRACTED ENTITIES:")
        print(f"   Proper Nouns: {entities.get('proper_nouns', [])}")
        print(f"   Objects: {entities.get('objects', [])[:5]}")
        print(f"   Actions: {entities.get('actions', [])}")
        print(f"   Numbers: {entities.get('numbers', [])}")
        print(f"   Locations: {entities.get('locations', [])}")
        
        # Step 2: Compute metrics
        metrics = compute_prompt_metrics(request.prompt, entities)
        print(f"\nðŸ“ˆ COMPUTED METRICS:")
        print(f"   Verbosity: {metrics.get('verbosity', 0):.2f}")
        print(f"   Energy: {metrics.get('energy', 0):.2f}")
        print(f"   Commercial Intensity: {metrics.get('commercial_intensity', 0):.2f}")
        print(f"   Brand Focus: {metrics.get('brand_focus', 0):.2f}")
        print(f"   Locality: {metrics.get('locality', 0):.2f}")
        print(f"   Visual Weight: {metrics.get('visual_weight', 0):.2f}")
        print(f"   Warmth: {metrics.get('warmth', 0):.2f}")
        
        # Step 3: Generate design
        blueprint = generative_generate_design(
            prompt=request.prompt,
            platform=request.platform,
            format=request.format
        )
        
        # Step 4: Generate AI Image using Hugging Face API
        ai_image_result = None
        hf_api_key = os.getenv("HUGGINGFACE_API_KEY", "")
        
        if hf_api_key:
            print(f"\nðŸ–¼ï¸ GENERATING AI IMAGE (Hugging Face API)...")
            
            # Create an image prompt based on the design
            brand_name = entities.get('proper_nouns', ['Product'])[0] if entities.get('proper_nouns') else 'Product'
            objects = entities.get('objects', [])[:3]
            
            # Build image generation prompt
            image_prompt = f"Professional advertisement image for {brand_name}"
            if 'coffee' in request.prompt.lower() or 'cafe' in request.prompt.lower() or 'shop' in request.prompt.lower():
                image_prompt = f"Beautiful coffee shop interior with warm lighting, cozy atmosphere, professional photography, cafe aesthetic, {brand_name}"
            elif 'fitness' in request.prompt.lower() or 'gym' in request.prompt.lower():
                image_prompt = f"Modern gym equipment, fitness motivation, energetic atmosphere, professional sports photography, {brand_name}"
            elif 'tech' in request.prompt.lower() or 'app' in request.prompt.lower() or 'software' in request.prompt.lower():
                image_prompt = f"Sleek technology product, modern UI interface, futuristic design, professional tech photography, {brand_name}"
            elif 'food' in request.prompt.lower() or 'restaurant' in request.prompt.lower():
                image_prompt = f"Delicious food photography, appetizing presentation, restaurant quality, professional food styling, {brand_name}"
            elif 'fashion' in request.prompt.lower() or 'clothing' in request.prompt.lower() or 'boutique' in request.prompt.lower():
                image_prompt = f"Fashion product photography, elegant styling, boutique aesthetic, professional fashion shoot, {brand_name}"
            elif objects:
                image_prompt = f"Professional advertisement featuring {', '.join(objects)}, high quality product photography, {brand_name}"
            
            try:
                ai_image_result = await image_generator.generate_ad_image(
                    prompt=image_prompt,
                    platform=request.platform,
                    format=request.format,
                    style="modern",
                    model="sdxl"  # Using SDXL - most reliable
                )
                
                if ai_image_result.get("success"):
                    print(f"   âœ… AI Image generated successfully!")
                    print(f"   ðŸ“ Size: {ai_image_result.get('width')}x{ai_image_result.get('height')}")
                    
                    # Add image to blueprint
                    blueprint["ai_image"] = {
                        "generated": True,
                        "prompt": image_prompt,
                        "model": ai_image_result.get("model"),
                        "image_data": ai_image_result.get("image_data"),
                        "width": ai_image_result.get("width"),
                        "height": ai_image_result.get("height"),
                    }
                else:
                    print(f"   âš ï¸ AI Image generation failed: {ai_image_result.get('error')}")
                    blueprint["ai_image"] = {
                        "generated": False,
                        "error": ai_image_result.get("error"),
                    }
            except Exception as img_error:
                print(f"   âŒ AI Image error: {img_error}")
                blueprint["ai_image"] = {
                    "generated": False,
                    "error": str(img_error),
                }
        else:
            print(f"\nâš ï¸ AI IMAGE SKIPPED - No HUGGINGFACE_API_KEY")
            print(f"   Set HUGGINGFACE_API_KEY in .env for AI image generation")
            blueprint["ai_image"] = {
                "generated": False,
                "error": "HUGGINGFACE_API_KEY not set. Add it to .env file.",
            }
        
        # Convert to Fabric.js format (include AI image if available)
        fabric_json = generative_blueprint_to_fabric(blueprint)
        
        # Add AI image to fabric objects if generated
        if blueprint.get("ai_image", {}).get("generated"):
            img_data = blueprint["ai_image"]["image_data"]
            width = blueprint["metadata"]["width"]
            height = blueprint["metadata"]["height"]
            
            # Add image as background or featured element
            fabric_json["objects"].insert(1, {
                "type": "image",
                "id": "ai_generated_image",
                "left": width * 0.1,
                "top": height * 0.15,
                "width": width * 0.35,
                "height": height * 0.35,
                "src": f"data:image/png;base64,{img_data}",
                "opacity": 0.95,
                "selectable": True,
                "evented": True,
                "scaleX": 1,
                "scaleY": 1,
            })
        
        # Log generated design details
        colors = blueprint.get("colors", {})
        layout = blueprint.get("layout", {})
        copy = blueprint.get("copy", {})
        
        print(f"\nðŸŽ¨ DERIVED COLORS (from prompt words):")
        print(f"   Base Hue: {colors.get('derived_hue', 0)}Â°")
        print(f"   Accent: {colors.get('accent', 'N/A')}")
        print(f"   Secondary: {colors.get('secondary', 'N/A')}")
        print(f"   Background: {colors.get('bg_primary', 'N/A')}")
        
        print(f"\nðŸ“ COMPUTED LAYOUT:")
        print(f"   Alignment: {layout.get('alignment', 'N/A')}")
        print(f"   Gradient Angle: {layout.get('gradient_angle', 0)}Â°")
        print(f"   Zones: {list(layout.get('zones', {}).keys())}")
        
        print(f"\nâœï¸ GENERATED COPY (from prompt words):")
        print(f"   Headline: {copy.get('headline', 'N/A').replace(chr(10), ' | ')}")
        print(f"   Subline: {copy.get('subline', 'N/A')}")
        print(f"   CTA: {copy.get('cta', 'N/A')}")
        print(f"   Badge: {copy.get('badge', 'None')}")
        print(f"{'='*70}\n")
        
        return DesignResponse(
            success=True,
            blueprint=blueprint,
            fabric_json=fabric_json,
            message=f"Design generated by GENERATIVE DESIGNER with AI Image" if blueprint.get("ai_image", {}).get("generated") else "Design generated (AI Image requires HUGGINGFACE_API_KEY)"
        )
    
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# AI IMAGE GENERATION ENDPOINT
# =============================================================================

class ImageGenerationRequest(BaseModel):
    """Request to generate an AI image"""
    prompt: str = Field(..., description="Image description")
    platform: str = Field(default="instagram", description="Target platform")
    format: str = Field(default="square", description="Image format")
    style: str = Field(default="modern", description="Style preset")
    model: str = Field(default="sdxl", description="AI model to use: sdxl, sdxl-turbo, sd-1-5, flux-schnell")

class ImageGenerationResponse(BaseModel):
    """AI image generation response"""
    success: bool
    image_data: Optional[str] = None
    image_url: Optional[str] = None
    width: Optional[int] = None
    height: Optional[int] = None
    model: Optional[str] = None
    error: Optional[str] = None
    message: Optional[str] = None

@app.post("/generate-image", response_model=ImageGenerationResponse)
async def generate_ai_image(request: ImageGenerationRequest):
    """
    Generate an AI image using Hugging Face API.
    Requires HUGGINGFACE_API_KEY to be set in environment.
    """
    try:
        hf_api_key = os.getenv("HUGGINGFACE_API_KEY", "")
        
        if not hf_api_key:
            return ImageGenerationResponse(
                success=False,
                error="HUGGINGFACE_API_KEY not set. Please add it to your .env file.",
                message="Get your free API key at https://huggingface.co/settings/tokens"
            )
        
        print(f"\nðŸ–¼ï¸ AI IMAGE GENERATION REQUEST")
        print(f"   Prompt: {request.prompt}")
        print(f"   Model: {request.model}")
        print(f"   Format: {request.format}")
        
        result = await image_generator.generate_ad_image(
            prompt=request.prompt,
            platform=request.platform,
            format=request.format,
            style=request.style,
            model=request.model
        )
        
        if result.get("success"):
            print(f"   âœ… Image generated: {result.get('width')}x{result.get('height')}")
            return ImageGenerationResponse(
                success=True,
                image_data=result.get("image_data"),
                image_url=result.get("image_url"),
                width=result.get("width"),
                height=result.get("height"),
                model=result.get("model"),
                message="Image generated successfully using Hugging Face API"
            )
        else:
            return ImageGenerationResponse(
                success=False,
                error=result.get("error", "Unknown error"),
                message="Image generation failed"
            )
            
    except Exception as e:
        import traceback
        traceback.print_exc()
        return ImageGenerationResponse(
            success=False,
            error=str(e),
            message="Image generation failed with exception"
        )

@app.get("/image-models")
async def get_image_models():
    """Get available AI image generation models"""
    return {
        "models": image_generator.get_available_models(),
        "styles": list(image_generator.get_style_presets().keys()),
        "api_configured": bool(os.getenv("HUGGINGFACE_API_KEY", ""))
    }


@app.get("/templates", response_model=TemplateListResponse)
async def get_templates():
    """Get list of available design templates"""
    
    templates = [
        {
            "id": "modern_product",
            "name": "Modern Product Launch",
            "category": "e-commerce",
            "thumbnail": "/templates/modern_product.png",
            "formats": ["square", "story", "landscape"]
        },
        {
            "id": "tech_promo",
            "name": "Tech Startup Promo",
            "category": "saas",
            "thumbnail": "/templates/tech_promo.png",
            "formats": ["square", "landscape"]
        },
        {
            "id": "flash_sale",
            "name": "Flash Sale",
            "category": "retail",
            "thumbnail": "/templates/flash_sale.png",
            "formats": ["square", "story"]
        },
        {
            "id": "fitness_motivation",
            "name": "Fitness Motivation",
            "category": "fitness",
            "thumbnail": "/templates/fitness.png",
            "formats": ["square", "story", "portrait"]
        },
        {
            "id": "minimalist_brand",
            "name": "Minimalist Brand",
            "category": "brand_awareness",
            "thumbnail": "/templates/minimalist.png",
            "formats": ["square", "landscape", "wide"]
        },
    ]
    
    return TemplateListResponse(templates=templates)

@app.post("/compliance", response_model=ComplianceCheckResponse)
async def check_compliance(request: ComplianceCheckRequest):
    """Check if a design complies with platform guidelines"""
    
    platform = request.platform.lower()
    blueprint = request.blueprint
    
    issues = []
    suggestions = []
    
    # Get platform guidelines
    guidelines = PLATFORM_GUIDELINES.get(platform, {})
    
    # Check text ratio (simplified)
    text_elements = [e for e in blueprint.get("elements", []) if e.get("type") == "text"]
    total_text_area = sum(
        (e.get("size", {}).get("width", 0) * e.get("size", {}).get("height", 0))
        for e in text_elements
    )
    
    max_ratio = guidelines.get("text_ratio_limit", 0.25)
    if total_text_area > (100 * 100 * max_ratio):  # Simplified calculation
        issues.append(f"Text may exceed {platform}'s recommended limit")
        suggestions.append("Consider reducing text size or removing some text elements")
    
    # Check for forbidden words
    forbidden = guidelines.get("forbidden_words", [])
    all_text = " ".join([
        e.get("content", "") for e in text_elements
    ]).lower()
    
    for word in forbidden:
        if word.lower() in all_text:
            issues.append(f"Contains potentially restricted word: '{word}'")
            suggestions.append(f"Consider replacing '{word}' with alternative phrasing")
    
    # Check color contrast (simplified)
    # In a real implementation, you'd calculate WCAG contrast ratios
    
    return ComplianceCheckResponse(
        compliant=len(issues) == 0,
        issues=issues,
        suggestions=suggestions if issues else ["Design looks compliant!"]
    )

@app.post("/refine")
async def refine_design(
    blueprint: Dict[str, Any],
    instruction: str,
):
    """Refine an existing design based on user feedback"""
    
    # This would use the model to modify the design
    # For now, return the same design with a note
    
    return {
        "success": True,
        "blueprint": blueprint,
        "message": f"Refinement noted: {instruction}. Model refinement coming soon."
    }


# =============================================================================
# RETAIL DESIGN ENDPOINTS
# =============================================================================

@app.post("/retail/generate", response_model=RetailCreativeResponse)
async def generate_retail_creative(request: RetailCreativeRequest):
    """
    Generate agency-grade retail creative for D2C, FMCG, and e-commerce.
    Returns design with variants and multi-platform formats.
    """
    try:
        generator = RetailDesignGenerator()
        
        # Map string platform to enum
        platform_map = {
            "instagram_feed": Platform.INSTAGRAM_FEED,
            "instagram_story": Platform.INSTAGRAM_STORY,
            "facebook_feed": Platform.FACEBOOK_FEED,
            "facebook_story": Platform.FACEBOOK_STORY,
            "amazon_main": Platform.AMAZON_MAIN,
            "amazon_lifestyle": Platform.AMAZON_LIFESTYLE,
            "flipkart_banner": Platform.FLIPKART_BANNER,
            "google_display": Platform.GOOGLE_DISPLAY,
        }
        
        tone_map = {
            "bold_fmcg": DesignTone.BOLD_FMCG,
            "premium_modern": DesignTone.PREMIUM_MODERN,
            "luxury_dark": DesignTone.LUXURY_DARK,
            "clean_retail": DesignTone.CLEAN_RETAIL,
            "vibrant_playful": DesignTone.VIBRANT_PLAYFUL,
            "tech_modern": DesignTone.TECH_MODERN,
            "trust_corporate": DesignTone.TRUST_CORPORATE,
        }
        
        platform = platform_map.get(request.platform, Platform.INSTAGRAM_FEED)
        tone = tone_map.get(request.tone, DesignTone.BOLD_FMCG)
        
        brand_config = {
            "brand_name": request.brand_name,
            "brand_colors": request.brand_colors,
            "logo_url": request.logo_url or ""
        }
        
        content = {
            "headline": request.headline,
            "subheadline": request.subheadline or "",
            "cta": request.cta,
            "offer": request.offer,
            "trust_signals": request.trust_signals or [],
            "products": request.products or [],
            "logo_url": request.logo_url or ""
        }
        
        # Generate primary design
        design = generator.generate_creative(
            brand_config=brand_config,
            content=content,
            platform=platform,
            tone=tone
        )
        
        # Generate variants
        variants = generator.generate_variants(design)
        
        # Generate all formats
        all_formats = generator.generate_all_formats(
            design,
            [Platform.INSTAGRAM_FEED, Platform.INSTAGRAM_STORY, 
             Platform.FACEBOOK_FEED, Platform.AMAZON_LIFESTYLE]
        )
        
        # Convert enum keys to strings for JSON serialization
        all_formats_serializable = {
            str(k.value) if hasattr(k, 'value') else str(k): v 
            for k, v in all_formats.items()
        }
        
        return RetailCreativeResponse(
            success=True,
            design=design,
            variants=variants,
            all_formats=all_formats_serializable,
            compliance=design.get("compliance", {}),
            message="Retail creative generated successfully"
        )
        
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/retail/palettes")
async def get_retail_palettes():
    """Get available retail color palettes"""
    return {
        "palettes": {
            name: {
                "name": palette["name"],
                "description": palette["description"],
                "preview": {
                    "primary": palette["primary"],
                    "accent": palette["accent"],
                    "background": palette["background"]["css"] if isinstance(palette["background"], dict) else palette["background"]
                }
            }
            for name, palette in RETAIL_COLOR_PALETTES.items()
        }
    }


@app.get("/retail/platforms")
async def get_retail_platforms():
    """Get supported platforms and their specifications"""
    return {
        "platforms": {
            platform.value: {
                "name": spec["name"],
                "dimensions": spec["dimensions"],
                "aspect_ratios": spec["aspect_ratios"],
                "max_file_size_kb": spec["max_file_size_kb"],
            }
            for platform, spec in PLATFORM_SPECS.items()
        }
    }


@app.get("/retail/demo")
async def get_retail_demo():
    """Get demo protein bar creative (as shown in the design brief)"""
    try:
        result = create_protein_bar_creative()
        return {
            "success": True,
            "demo_creative": result,
            "message": "Demo creative for Plant-Based Protein Bar campaign"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/retail/compliance-check")
async def check_retail_compliance(
    design: Dict[str, Any],
    platform: str
):
    """Run AI compliance check on a retail design"""
    try:
        platform_map = {
            "instagram_feed": Platform.INSTAGRAM_FEED,
            "instagram_story": Platform.INSTAGRAM_STORY,
            "facebook_feed": Platform.FACEBOOK_FEED,
            "amazon_main": Platform.AMAZON_MAIN,
            "amazon_lifestyle": Platform.AMAZON_LIFESTYLE,
            "flipkart_banner": Platform.FLIPKART_BANNER,
        }
        
        platform_enum = platform_map.get(platform, Platform.INSTAGRAM_FEED)
        
        compliance_engine = ComplianceEngine()
        result = compliance_engine.check_design(design, platform_enum)
        
        return {
            "success": True,
            "compliance": result,
            "is_compliant": result["summary"]["is_compliant"],
            "message": "Compliance check completed"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/retail/auto-fix")
async def auto_fix_retail_design(
    design: Dict[str, Any],
    platform: str
):
    """Apply AI auto-fixes to resolve compliance issues"""
    try:
        platform_map = {
            "instagram_feed": Platform.INSTAGRAM_FEED,
            "instagram_story": Platform.INSTAGRAM_STORY,
            "facebook_feed": Platform.FACEBOOK_FEED,
            "amazon_main": Platform.AMAZON_MAIN,
        }
        
        platform_enum = platform_map.get(platform, Platform.INSTAGRAM_FEED)
        
        compliance_engine = ComplianceEngine()
        result = compliance_engine.auto_fix_all(design, platform_enum)
        
        return {
            "success": True,
            "fixed_design": result["design"],
            "fixes_applied": result["fixes_applied"],
            "remaining_issues": result["remaining_issues"],
            "message": f"Applied {len(result['fixes_applied'])} auto-fixes"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# DESIGN STORAGE ENDPOINTS
# =============================================================================

import os
from datetime import datetime
import base64

# Storage directory for generated designs
DESIGNS_DIR = Path("generated_designs")
DESIGNS_DIR.mkdir(exist_ok=True)


@app.post("/save-design")
async def save_design(
    design_id: str,
    design_data: Dict[str, Any],
    image_data: Optional[str] = None  # Base64 encoded image
):
    """Save a generated design to storage"""
    try:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Save design JSON
        design_path = DESIGNS_DIR / f"{design_id}_{timestamp}.json"
        with open(design_path, "w") as f:
            json.dump(design_data, f, indent=2, default=str)
        
        image_path = None
        
        # Save image if provided
        if image_data:
            # Remove data URL prefix if present
            if image_data.startswith("data:image"):
                image_data = image_data.split(",")[1]
            
            image_bytes = base64.b64decode(image_data)
            image_path = DESIGNS_DIR / f"{design_id}_{timestamp}.png"
            with open(image_path, "wb") as f:
                f.write(image_bytes)
        
        return {
            "success": True,
            "design_id": design_id,
            "design_path": str(design_path),
            "image_path": str(image_path) if image_path else None,
            "timestamp": timestamp
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/saved-designs")
async def list_saved_designs():
    """List all saved designs"""
    try:
        designs = []
        for file in DESIGNS_DIR.glob("*.json"):
            with open(file, "r") as f:
                design = json.load(f)
                designs.append({
                    "filename": file.name,
                    "design_id": file.stem.split("_")[0],
                    "created": file.stat().st_mtime,
                    "has_image": (file.with_suffix(".png")).exists()
                })
        
        return {
            "success": True,
            "count": len(designs),
            "designs": sorted(designs, key=lambda x: x["created"], reverse=True)
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/generation-status")
async def generation_status():
    """Get current status of design generation capabilities"""
    return {
        "service": "AdGenesis ML Design Service",
        "version": "3.0.0",
        "capabilities": {
            "trained_model": {
                "available": model_loaded,
                "model_type": "GPT-2 Medium with LoRA fine-tuning",
                "status": "active" if model_loaded else "not_loaded"
            },
            "rule_based": {
                "available": True,
                "status": "active (fallback)"
            },
            "retail_system": {
                "available": True,
                "palettes": len(RETAIL_COLOR_PALETTES),
                "platforms": len(PLATFORM_SPECS)
            }
        },
        "generation_priority": [
            "1. Trained ML Model (if loaded and generates valid output)",
            "2. Rule-Based Modern Design System (fallback)"
        ],
        "storage": {
            "directory": str(DESIGNS_DIR),
            "saved_designs": len(list(DESIGNS_DIR.glob("*.json")))
        }
    }

# =============================================================================
# STARTUP
# =============================================================================

@app.on_event("startup")
async def startup():
    """Load model on startup"""
    # Try to load the design model
    model_paths = [
        "models/fine_tuned/design_model",
        "models/fine_tuned/gpt2",
    ]
    
    for path in model_paths:
        if Path(path).exists():
            if load_model(path):
                break
    
    if not model_loaded:
        print("âš ï¸ No model loaded. Using rule-based generation.")

# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    import argparse
    
    parser = argparse.ArgumentParser()
    parser.add_argument("--model-path", type=str, default="models/fine_tuned/design_model")
    parser.add_argument("--port", type=int, default=8001)
    parser.add_argument("--host", type=str, default="0.0.0.0")
    args = parser.parse_args()
    
    # Load model
    load_model(args.model_path)
    
    # Run server
    uvicorn.run(app, host=args.host, port=args.port)
